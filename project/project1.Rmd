---
title: "CompBioProject-1-TJR2489"
author: "Tyler Roquebert"
date: "2/25/2021"
output: html_document
---

```{r eval=F}
#formatting setup
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```

# Spotify Data Project!

## Setting up Library
```{r spotify data import}
library(jsonlite)
library(tidyverse)
library(knitr)
library(lubridate)
library(kableExtra)
```

## Installing 'spotifyr' package and acquiring Spotify Web API Access
```{r spotifyr package install}
#downloading the package 'spotifyr' from GitHub
# devtools::install_github('charlie86/spotifyr')
library(spotifyr)

#acquiring Spotify API access
Sys.setenv(SPOTIFY_CLIENT_ID = "903fbc26394c4d3a8f4952eaf3681fd3")
Sys.setenv(SPOTIFY_CLIENT_SECRET = "12d6d93453074c8e8caecd14ef9f68b4")
access_token <- get_spotify_access_token()
```

## Pulling in My Top Songs of 2020 Playlist, the Track Audio Features, and Joining Together
``` {r My 2020 Top Tracks}
# my_plists <- get_my_playlists() #successfully acquires my 20 most recently added/liked/created playlists
#turns playlist into a single row in df; obtained the playlist id from it
# top_2020_playlist <- my_plists %>% filter(name %in% c("Your Top Songs 2020"))
#successfully returns all 100 tracks in the my Top 2020 playlist, using the Spotify playlist id - doesn't include track_audio_features
top_2020_tracks <- get_playlist_tracks(playlist_id = '37i9dQZF1EM9Jj6kqpNa6l')
#getting audio features for all 100 unique songs in the Top 2020 playlist using lapply
audio_feat <- lapply(list(top_2020_tracks$track.id), get_track_audio_features)
#binding track audio feature data into a clean df
audio_feat <- do.call('rbind', audio_feat)
#joining Track Audio Feature data with Track listing df; keeping the original track data intact and adding in 17 variables (40 to 57)
top_2020_track_features <- top_2020_tracks %>% left_join(audio_feat, by = c("track.id" = "id"))
```

## Tidying the Top 2020 Tracks to Include Relevant Variables
``` {r Tidying TopTracks Data}
#grabbing data on tracks; many columns in original df were extraneous or duplicates to some extent (user url vs playlist url)
toptrackstidy <- top_2020_track_features %>%
  select(14,16,18,19,22,24,25,26,29,30,31,32,34,37,38,39,41,42,43,44,45,46,47,48,49,50,51,56,57)
#rearranging columns to pull track name to front, followed by if it's from album or single, the album's name, and then everything else
toptrackstidy <- toptrackstidy %>% select(track.name, track.album.album_type, track.album.name, everything())
#renaming everything to my liking
toptrackstidy <- toptrackstidy %>% rename(album_type=track.album.album_type, album_name=track.album.name, explicit=track.explicit, track_id=track.id, track_popularity=track.popularity, track_number=track.track_number,track_uri=track.uri, album_artists=track.album.artists, album_id=track.album.id, album_images=track.album.images, album_release_date=track.album.release_date, tracks_in_album=track.album.total_tracks, album_external_url=track.album.external_urls.spotify, track_external_ids=track.external_ids.isrc, track_external_url=track.external_urls.spotify)
#getting the explicit designation from logical, to numeric, and finally to categorical to group by later
toptrackstidy <- toptrackstidy %>% mutate(explicit = as.numeric(explicit))
#using case_when function to force explicit designation to a categorical variable (one of the better grouping categories ive got)
toptrackstidy <-toptrackstidy %>% mutate(explicit = case_when(explicit > 0 ~ "yes", explicit < 1 ~ "no"))
#a sneak peak!
glimpse(toptrackstidy)
```


## Creating Summary Statistics 
```{r Creating Summary Statistics}
#using mutate() to add new variables for track length in seconds and then minutes. originally in milliseconds, precise but hard to read
toptrackstidy <- toptrackstidy %>% 
  mutate(duration_sec = duration_ms/1000) %>%
  mutate(duration_min=duration_sec/60)
#playing with select() and filter() based on danceability and speechiness scores --> only three songs met this requirement in my top 100!
toptrackstidy %>% select(track.name, track_popularity, danceability, speechiness) %>% 
  filter(danceability >= 0.5, speechiness >= 0.5) %>% kable() %>% kable_styling()
#playing with select() and arrange() based on danceability values
toptrackstidy %>% select(track.name, track_popularity, danceability) %>% 
  arrange(desc(danceability)) %>% head(10) %>% kable() %>% kable_styling()
#using group_by() to group by the number of tracks in an album (if album or single), then adding columns for mean/sd of danceability
toptrackstidy %>% group_by(explicit) %>% 
  summarize_at(17:20, list(mean=mean, sd=sd, median=median, ndistinct=n_distinct)) %>% 
  kable() %>% kable_styling() 

#making summary statistics of mean, sd, min, max for 12 of my numeric variables
sum_stats_top_tracks <- toptrackstidy %>% summarize_at(17:27, 
                                                       list(min=min, max=max, mean=mean, sd=sd,
                                                            median=median, ndistinct=n_distinct))
#need to reshape the df i created above with summary statistics to make it presentable and usable later
sum_stats_top_tracks %>% pivot_longer(contains("_")) %>% 
  separate(name, into = c("audio_features", "var"), sep = "\\_") %>% 
  pivot_wider(names_from = "var", values_from = "value") %>% 
  kable() %>% kable_styling()
```
The table above describes the minimum, maximum, mean, standard deviation, median, and number of distinct values for each of the 11 audio features. There were 100 observations within the dataset, representing my Top 100 songs of 2020. The standard deviation across all audio features is small with the exception of tempo. The tempo of a song in beats per minute influences the energy and danceability as well, so it's surprising to not see greater variation in those categories as well. One feature in this table that sticks out would be the audio feature mode - which indicates whether the track is recorded in a Major or Minor scale. This was represented as binary values (0 or 1), so there are only 2 distinct values and a large difference between the mean and median in this category. In conclusion, the average values of each individual category don't reflect too much about my individual listening history. A better way to understand my listening is through visualizations which are to follow!

```{r summary stats for grouped by variables}
#creating summary stats based off of a grouping variable (is a song from an album or single) 
grouped_sum_stats <- toptrackstidy %>% group_by(album_type) %>% summarize_at(17:26, list(min=min, max=max, mean=mean, 
                                                                                         sd=sd,median=median, 
                                                                                         ndistinct=n_distinct))
#this table shows summary statistics for 10 audio features based off of whether the song was from a single or an album
grouped_sum_stats %>% pivot_longer(cols = -1) %>% 
  separate(name, into = c("audio_features", "var"), sep = "\\_") %>% 
  pivot_wider(names_from = "var", values_from = "value") %>% 
  kable() %>% kable_styling()
```
This table shows the same summary statistics as the one above, but the tracks have been categorized by the nature of their release: whether they were released as a single or part of an album. 
```{r Creating the Correlation Matrix}
#making a correlation matrix of numeric variables (aka the audio_features)
cormatrix <- toptrackstidy %>% select(17:27) %>% cor(use = "pair")
cormatrixtidy <- cormatrix %>% 
  as.data.frame() %>% 
  rownames_to_column("audio_feat1") %>% 
  pivot_longer(-1, names_to = "audio_feat2", values_to = "correlation")
#shows that the correlation matrix was successfully pivoted to a cleaner df; this will be used to plot below. 
cormatrixtidy %>% head(5) %>% kable() %>% kable_styling()
```

## Time to Plot!
``` {r Correlation Heatmap}
cormatrixtidy %>% ggplot(aes(audio_feat1, audio_feat2, fill=correlation)) + geom_tile() +
scale_fill_gradient2(low="orange",mid="white",high="purple")+ 
geom_text(aes(label=round(correlation,3)),color = "navy", size = 3)+
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("Correlation Heat-Map for Numeric Audio Features")
```
*There were 11 relevant audio features that I was able to pull from Spotify's API. When viewing the correlation heat-map of the 11 numeric audio features, the strongest observed correlation (besides to itself) is between loudness and energy. Considering loudness is measured in decibels and energy is a "perceptual measure of intensity and activity" - where heavy metal would be most energetic - this is not a surprising correlation. Another moderate correlation that I find interesting is that between Valence and Energy. Valence is described as the overall positivity of the track, and energy is a different-but-similar measurement, so it's reassuring seeing they have a moderate correlation in my top 100 tracks of 2020.*

I was able to find a really useful website that has a complete description of all the variables Spotify keeps on tracks. I'd like to link it here so that references in my explanations have supporting evidence, and because I figured you'd like to see what this person was able to do with their dataset. Link: https://rpubs.com/PeterDola/SpotifyTracks#:~:text=Some%20of%20the%20variables%20are,confidence%20the%20track%20is%20acoustic.

``` {r Scatterplot mapping danceability, speechinness, instrumentalness, and explicit designation}
toptrackstidy %>% ggplot(aes(x=danceability, y=speechiness)) + 
  geom_point(aes(color=explicit, size = instrumentalness)) + 
  theme_light()+
  scale_x_continuous(breaks = c(0, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0))+
  scale_y_continuous(breaks = c(0, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0))+
  ggtitle("Relationship Between Speechiness, Danceability, and Instrumentalness of Track")
```
*The scatterplot above shows the relationship between speechiness scores and danceability values. The color of the dots represents if the song was explicit or not, and the dot size correlates to the instrumentalness score assigned to the song. The most apparent trend is that the highest scoring tracks in instrumentalness tended to score lowest on speechiness - not surprising considering more spoken word (like rap) tends to have less accompanying instruments. Furthermore, my top 100 songs of 2020 that were not explicit scored lower on speechiness than about half of the explicit songs. My favorite genre of music is hip-hop/rap, and songs in that genre tend to be explicit AND full of spoken word (high speechiness values), so the rough trend observed above verifies this assumption!*

``` {r Last Plot}
#changing the song's key designation from numeric to categorical variables for easier reading; done using integer-pitch notation
toptrackstidykey <- toptrackstidy %>% 
  mutate(key = case_when(key > 10 ~ "B", key<=10 & 9<key ~ "B.flat",
                                         key<=9 & 8<key ~ "A",
                                         key<=8 & 7<key ~ "G.sharp",
                                         key<=7 & 6<key ~ "G",
                                         key<=6 & 5<key ~ "F.sharp",
                                         key<=5 & 4<key ~ "F",
                                         key<=4 & 3<key ~ "E",
                                         key<=3 & 2<key ~ "D.sharp",
                                         key<=2 & 1<key ~ "D",
                                         key<=1 & 0<key ~ "C.sharp",
                                         key<= 0 ~ "C"))
#plotting the average popularity of a track based on what key the track(s) were in; also split into categories based on whether the song was released as a single or part of an album
ggplot(toptrackstidykey, aes(x=key, y=track_popularity))+ 
  geom_bar(stat = "summary", aes(fill=album_type), position = "dodge") + 
  theme(legend.position = "top")+
  scale_y_continuous(name = "Average Track Popularity")+
  scale_x_discrete(name = "Track's Key") +
  ggtitle("Average Track Popularity Based on Song's Key and Type of Track Release")
```
*The bar chart above shows the average popularity of tracks based on what key the song(s) was in. The data is broken down further based on whether the song was released as a single or part of an album. Track popularity is rated on a 0-100 scale, with 100 being the most popular. Songs in the key F-sharp from an album have the highest average song popularity; meanwhile, songs released as a single experienced the greatest average popularity in the key D-natural. Tracks released as part of an album had higher average popularity scores in all keys except for B-flat and D-natural. Finally, it looks like singles in the key D-sharp were not high on people's listening list in 2020, as it received the lowest average track popularity (from the 2 songs out of my top 100 that were in this key*

## PAM Clustering on Selected Numeric Variables
``` {r Subsetting and finding optimal number of clusters}
library(cluster)
#pulling the numeric variables of interest from original dataset; selecting the 14 most representative of audio features to include in PAM
data_to_clust <- toptrackstidy %>% 
  select(6,17,18,19,20,21,22,23,24,25,26,27,28,29)

#using loop to find optimal number of clusters - using 14 numeric variables to predict! the loop performs a PAM clustering analysis for n-number of clusters. PAM clustering 
sil_width<-vector()
for (i in 2:12) {
  pam_fit <- pam(data_to_clust, k = i)
  sil_width[i] <- pam_fit$silinfo$avg.width
}
#the plot below indicates that the optimal number of clusters is 5! 
ggplot()+geom_line(aes(x=1:12,y=sil_width))+
  scale_x_continuous(name="k (number of clusters)",breaks=1:12) +
  scale_y_continuous(name="Average Silhouette Width")+
  ggtitle("Average Silhouette Width for Each No. of Clusters")

#clustering with k=5, based off of previous plot indicating the average silhouette width is MAXIMIZED when there are 5 clusters
tracks_pam <- data_to_clust %>% pam(k=5)
tracks_pam
#our average silhoutte width with a cluster number of 5 is 0.5989. When interpreting cluster strength, the average silhouette width indicates that a reasonable structure has been found.
tracks_pam$silinfo$avg.width
```
Average silhouette width is a measurement which describes the quality of the clustering after performing PAM clustering analysis. Silhouette width can be thought of as the inverse of the within-cluster variation and linearly related to between-cluster variation; when the variation among points within clusters is minimized - then the silhouette width is maximized. Conversely, when the variation between clusters is maximized, average silhouette width increases. Thus, the greater the average silhouette width, the stronger the cluster structure pattern is since it can be thought of a measurement for how cohesive and separated clusters are simultaneously. Plotting average silhouette width for a range of k clusters reveals how many clusters may be optimal for the data. The average silhouette width is maximized when k=5 for the top tracks data; at k=5 there a reasonable cluster structure has been found with average silhouette width equal to 0.5989.

```{r }
plot(tracks_pam, which=2)
```

The plot above reveals the distribution of our cluster data, and confirms that the average silhouette width is approximately 0.60. 
```{r adding in cluster designation to audio feature numeric data}
#using mutate(), added clustering results (1-5) to the dataset containing all audio feature numeric variables; & saved it all as clustdat
clustdat <- data_to_clust %>%
  mutate(cluster=as.factor(tracks_pam$clustering))
#provides the mean value of each audio feature based on the cluster grouping
clustdat%>%group_by(cluster)%>%
  summarize_if(is.numeric,mean,na.rm=T) %>% 
  kable() %>% kable_styling()
```
The table above shows the mean value for each audio feature based on/or within each cluster. The audio features with the greatest difference between clusters appear to be track popularity, key, and danceability scores (at cluster 4). 

``` {r medoids of the clusters}
#below are exact points in each cluster which represent the cluster's medoid. the medoid is the most representative point (which comes from the dataset and is not generated) of the cluster it is in.
clustdat %>% slice(tracks_pam$id.med) %>% 
  select(cluster, everything()) %>% 
  kable() %>% kable_styling()
```
The table above gives the observation within each cluster that represents that cluster's specific medoid. The medoid of a cluster can be described as the most representative point within that cluster. In PAM clustering, the medoid represents an actual observation in the data; meanwhile, k-means clustering generates a centroid to represent the cluster but it does not represent an actual point in the data. Interestingly, 4 of the distinct cluster medoids had the same two keys (F-sharp = 6, G-sharp = 8). There were only 10 distinct keys among my top 100 songs, so this may have lowered the ability to differentiate between clusters based on key. 

``` {r cool plots!}
#scatterplot showing relationship between song tempo (bpm) and a song's valence (positivity of track), based on cluster designation
#scatterplot below isn't a great representation because it captures only 2 dimensions of our clusters - and there were 14 numeric variables that were used in the PAM clustering (across 5 clusters)
clustdat %>% ggplot(aes(tempo, valence, color=cluster))+geom_point() + 
  theme_dark(base_size = 13)+
  scale_y_continuous(name="Track's Valence (positivity score)")+
  scale_x_continuous(name="Track's Tempo (beats/min)")+
  ggtitle("Relationship Between Valence and Tempo By Cluster")
```
The scatterplot above depicts the relationship between valence and tempo between the five different clusters. This scatterplot only includes two numeric variables to visualize the clustering relationship; considering there were 14 numeric audio features that were included in the PAM clustering, visualizing based off of two is not very indicative of the overall pattern. Thus, the clusters don't appear to follow any sort of pattern in this plot. 

``` {r 4D plot using valence, tempo, danceability, and mode}
library(plotly)
clustdat %>% plot_ly(x= ~tempo, y = ~valence, z = ~danceability, color = ~cluster,
                     type = "scatter3d", mode = "markers", symbol = ~mode, symbols = c('circle', 'square'), opacity = 0.75) %>% layout(
    title = "3D Cluster Visualization: Relationship Between Danceability, Valence, and Tempo", 
    scene = list(
      xaxis = list(title = "Tempo (beats/min)"),
      yaxis = list(title = "Valence (positivity)"),
      zaxis = list(title = "Danceability Rating"))) %>% 
  layout(legend=list(title=list(text='<b> Clusters </b>')))
```

The plot above provides a better visualization of our clustering pattern by including more numeric audio feature predictors. The four-dimensional scatterplot has danceability values mapped to the z axis, song tempo mapped to the x axis, and song valence (positivity) mapped to the y axis. Furthermore, the points are colored by what cluster they belong to (1-5), and the shape of the point indicates the modality of the track: square represents a melody in a Major key, circle represents a melody in a Minor key. This visualization indicates a better cluster organization than the 2-dimensional ggplot above; but, the cluster organization is still not distinct enough to be perceptible at a glance. It would be useful to visualize other 4D plots using different numeric audio feature predictors to determine if one set of 3 are better predictors than others. 




