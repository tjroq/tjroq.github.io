<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Tyler Roquebert" />
    
    <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico">
    <title>TJR2489_Project2_Sp2021 - Modeling, Testing, and Prediction</title>
    <meta name="generator" content="Hugo 0.83.1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="/css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="/"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="/post/">BLOG</a></li>
        
        <li><a href="/projects/">PROJECTS</a></li>
        
        <li><a href="/resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="/project/project2/">TJR2489_Project2_Sp2021 - Modeling, Testing, and Prediction</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         January 1, 0001 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="building-prediction-and-estimate-models-for-ea-sports-fifa-21-soccer-players" class="section level1">
<h1>Building Prediction and Estimate Models for EA Sports’ FIFA 21 Soccer Players</h1>
<div id="introduction-to-fifa21-and-futbin-data" class="section level2">
<h2>Introduction to FIFA21 and FutBin Data</h2>
<p>The latest addition of EA Sports’ worldwide hit video game is FIFA 21, released on October 6th, 2020. FIFA allows users to play with their favorite soccer stars in a fast-paced football (soccer) simulation which tests users IQ, reactions, and decision making skills through the course of a game (12-15 real minutes). FIFA Ultimate Team (FUT) is a game mode where users can buy/sell players throughout the year to try and build the squad of their dreams. Furthermore, FUT fosters a sense of extreme competition because users can compete against each other 1v1 (or co-op) to find out who’s the best FIFA player around. Considering over 10 million copies of FIFA20 were sold the year prior, competition is never scarce in FUT. Thus, users are compelled to keep playing to generate coins and performance based rewards, to continually upgrade their Ultimate Team.</p>
<p>The website Futbin.com represents the Holy Grail of information for any serious FUT player. FutBin continually monitors the in-game (FIFA 21 FUT) transfer market, and updates player prices within their database accordingly. Furthermore, the full statistical profile, mental attributes, and skills of any given player (known as in-game stats) are incorporated in FutBin’s data. Thus, casual-to-professional FUT users can compare the price or statistics of any player they want from the FIFA 21 game, allowing the user to fine-tune their Ultimate Team.</p>
<p>Players are broken down into six key statistics: Pace, Shooting, Passing, Dribbling, Defending, and Physical. Within each of these six measurements exists subcategories which further explain the measurement; examples include Crossing and Vision in the Passing measurement or Strength and Stamina in the Physical measurement. The six core measurements and their subcategories are rated on a 1-100 scale for each player. Furthermore, players are given a designation for how comparable their weak foot is to their dominant foot (rated 1-5 stars); and the same scale is used for how well a player can perform skill moves in-game. Ultimate Team and FutBin also keep tabs of a player’s position, height, weight, nationality, and what football club they play for. Ultimately, the rating a player receives (1-100) determines the type of FUT “card” they receive (Bronze, Silver, Gold); each of these can be broken down into Rare of Non-Rare card as well. Finally, there are a select number of past players (retirees) who are included in the game as Icons. Icon players are special because they allow users to play with some of their all-time favorite players (Frank Lampard, for a Chelsea fan’s example), and, their ratings tend to be <strong>very</strong> good.</p>
<p>This project will use data obtained from FutBin’s FIFA 21 registry. After cleaning the data to remove unwanted variables, rows which contained NAs, Goal Keepers, and duplicate (but special i.e. Halloween version) cards, the dataset contains 55 complete columns for 3,323 players in FIFA 21.</p>
<pre class="r"><code># importing dataset containing data on each soccer player in FIFA21; also includes their auction/transfer market price (for some)
fut_bin21_players &lt;- read_csv(&quot;~/Desktop/website/content/project/fut_bin21_players.csv&quot;)

futbin_players &lt;- fut_bin21_players %&gt;% 
  select(player_name, player_extended_name, quality, revision, overall, club, league, nationality, position, age, height, weight, intl_rep, pace, pace_acceleration, pace_sprint_speed, dribbling, drib_agility, drib_balance, drib_reactions, drib_ball_control, drib_dribbling, drib_composure, shooting, shoot_positioning, shoot_finishing, shoot_shot_power, shoot_long_shots, shoot_volleys, shoot_penalties, shoot_penalties, passing, pass_vision, pass_crossing, pass_free_kick, pass_short, pass_long, pass_curve, defending, def_interceptions, def_heading, def_marking, def_stand_tackle, def_slid_tackle, physicality, phys_jumping, phys_stamina, phys_strength, phys_aggression, pref_foot, att_workrate, def_workrate, weak_foot, skill_moves, ps4_last, ps4_min, ps4_max, ps4_prp)</code></pre>
<p>Above, I’ve pulled the most relevant statistics gathered on players. It includes all of the numeric statistics, and their categorical variables which were discussed briefly above.</p>
<pre class="r"><code>outfield_players &lt;- futbin_players %&gt;% filter(!position == &quot;GK&quot;)

full_outfield_players &lt;- outfield_players %&gt;% na.omit() # removing all rows w NAs in the data; deletes (15,779-15,055) 724 rows

# created dataset that contains only player values, and filtered to only get players &#39;base&#39; cards (bronze-gold &amp; icon)
# bronze through gold cards are further designated as Rare or Non-Rare cards. 
tidy_nameless_players &lt;- full_outfield_players %&gt;% 
  select(-1,-2) %&gt;% 
  filter(revision == c(&quot;Icon&quot;, &quot;Rare&quot;, &quot;Non-Rare&quot;, &quot;non-rare&quot;)) %&gt;% 
  mutate(revision = str_replace(revision, &quot;non-rare&quot;, &quot;Non-Rare&quot;))

# building set with only the SIX CORE numeric statistics for a player&#39;s rating since the one above has SO many numeric variables
tidier_nameless_players &lt;- tidy_nameless_players %&gt;% 
  select(revision, overall, club, league, nationality, position, age, height, weight, intl_rep, pace, dribbling, shooting, passing, defending, physicality, pref_foot, att_workrate, def_workrate, weak_foot, skill_moves, ps4_last, ps4_prp)</code></pre>
<p>Above, I’ve removed Goal Keepers from the dataset and kept only outfield soccer players. Goal Keeper statistics are measured differently than outfield players, so for consistency and ease of use sake, they were removed. Still, over 15,000 players remain in the dataset.
Next, I remove any rows/observations which contained NA values. The majority of rows (724) removed held NAs for their auction price data; coincidentally, these are some of the most revered and wanted players in the game (Pele, Ronaldinho) and tend not to be sold when acquired.
Finally, I’ve removed player’s names from the dataset since they would make too good of a predictor later. Also, I’ve removed player cards that are “special”. Without going into excruciating detail, these are either cards that are not based on real-life performance (like a Halloween edition) or are not classified properly for this project.</p>
</div>
<div id="manova-testing" class="section level2">
<h2>MANOVA Testing</h2>
<pre class="r"><code># MANOVA testing whether these 5 numeric variables judging a player&#39;s abilities differ based on if the player is non-rare, rare, or Icon (intuitively yes)

# overall rating, pace, physicality, weak foot, and skill move ratings were chosen because as an active FIFA/FUT player myself, I can say that these traits are notable when finding suitable players to purchase (especially Pace)
man1 &lt;- 
  manova(cbind(overall, pace, physicality, weak_foot, skill_moves)~revision,
         data=tidier_nameless_players)
summary(man1) # shows a significant mean difference between numerics across the 3 levels of Revision (rare or not, and Icon)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## revision 2 0.2109 78.201 10 6634 &lt; 2.2e-16 ***
## Residuals 3320
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>A one-way MANOVA was conducted to determine the effect of a player’s card type (Non-Rare, Rare, or Icon) on five dependent variables (overall rating, pace, physicality, weak foot, and skill moves). Significant differences were found among the three card types for at least one of the dependent variables, even after comparing to the Bonferroni corrected level of significance (<em>Pillai trace</em> = 0.211, <em>pseudo F</em>(10,6,634) = 78.201, <em>p</em> &lt; 0.0001).</p>
<pre class="r"><code>summary.aov(man1) # performs univariate ANOVAs from the given MANOVA object</code></pre>
<pre><code>## Response overall :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## revision 2 31362 15681.0 368.06 &lt; 2.2e-16 ***
## Residuals 3320 141446 42.6
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response pace :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## revision 2 19431 9715.3 78.523 &lt; 2.2e-16 ***
## Residuals 3320 410769 123.7
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response physicality :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## revision 2 12524 6262.2 69.925 &lt; 2.2e-16 ***
## Residuals 3320 297327 89.6
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response weak_foot :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## revision 2 33.57 16.7834 38.5 &lt; 2.2e-16 ***
## Residuals 3320 1447.30 0.4359
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response skill_moves :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## revision 2 83.71 41.854 103.29 &lt; 2.2e-16 ***
## Residuals 3320 1345.28 0.405
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code># significant result in ALL FIVE univariate ANOVA tests reveal that for all 5 of the numeric variables, at least one type of card&#39;s average in that category is different than the other card types! </code></pre>
<p>Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA to test for significant differences between card types within <em>each</em> numeric variable, using the Bonferroni method for controlling Type I error rates for multiple comparisons. The univariate ANOVAs for Overall Rating, Pace, Physicality, Weak Foot, and Skill Moves were also significant, <em>F</em>(2,3320) = 368.06, <em>p</em> &lt; .0001; <em>F</em>(2,3320) = 78.523, <em>p</em> &lt; .0001; <em>F</em>(2,3320) = 69.925, <em>p</em> &lt; .0001; <em>F</em>(2,3320) = 38.5, <em>p</em> &lt; .0001; <em>F</em>(2,3320) = 103.29, <em>p</em> &lt; .0001, respectively.</p>
<pre class="r"><code>tidier_nameless_players %&gt;% group_by(revision) %&gt;% 
  summarize(mean_OVR=mean(overall), 
            mean_pace=mean(pace), mean_phys=mean(physicality), 
            mean_WF=mean(weak_foot), mean_SM=mean(skill_moves)) %&gt;% 
  kable(&quot;pipe&quot;, digits = 3, caption = &quot;Average Stat Grade by Card Type&quot;)</code></pre>
<table>
<caption>(#tab:t tests from ANOVAs)Average Stat Grade by Card Type</caption>
<thead>
<tr class="header">
<th align="left">revision</th>
<th align="right">mean_OVR</th>
<th align="right">mean_pace</th>
<th align="right">mean_phys</th>
<th align="right">mean_WF</th>
<th align="right">mean_SM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Icon</td>
<td align="right">88.209</td>
<td align="right">83.581</td>
<td align="right">75.791</td>
<td align="right">3.814</td>
<td align="right">3.535</td>
</tr>
<tr class="even">
<td align="left">Non-Rare</td>
<td align="right">65.289</td>
<td align="right">66.695</td>
<td align="right">64.315</td>
<td align="right">2.987</td>
<td align="right">2.496</td>
</tr>
<tr class="odd">
<td align="left">Rare</td>
<td align="right">69.243</td>
<td align="right">70.168</td>
<td align="right">67.586</td>
<td align="right">3.083</td>
<td align="right">2.742</td>
</tr>
</tbody>
</table>
<pre class="r"><code>pairwise.t.test(tidier_nameless_players$overall, tidier_nameless_players$revision, p.adj=&quot;none&quot;) # overall rating across card types</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: tidier_nameless_players$overall and
tidier_nameless_players$revision
##
## Icon Non-Rare
## Non-Rare &lt;2e-16 -
## Rare &lt;2e-16 &lt;2e-16
##
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(tidier_nameless_players$pace, tidier_nameless_players$revision, p.adj=&quot;none&quot;) # pace across card types</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: tidier_nameless_players$pace and
tidier_nameless_players$revision
##
## Icon Non-Rare
## Non-Rare &lt; 2e-16 -
## Rare 1.1e-14 &lt; 2e-16
##
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(tidier_nameless_players$physicality, tidier_nameless_players$revision, p.adj=&quot;none&quot;) # physical across card types</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: tidier_nameless_players$physicality and
tidier_nameless_players$revision
##
## Icon Non-Rare
## Non-Rare 4.7e-15 -
## Rare 2.6e-08 &lt; 2e-16
##
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(tidier_nameless_players$weak_foot, tidier_nameless_players$revision, p.adj=&quot;none&quot;) # weak foot across card types</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: tidier_nameless_players$weak_foot and
tidier_nameless_players$revision
##
## Icon Non-Rare
## Non-Rare 5.9e-16 -
## Rare 1.2e-12 7.6e-05
##
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(tidier_nameless_players$skill_moves, tidier_nameless_players$revision, p.adj=&quot;none&quot;) # skill moves across card types</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: tidier_nameless_players$skill_moves and
tidier_nameless_players$revision
##
## Icon Non-Rare
## Non-Rare &lt; 2e-16 -
## Rare 1.5e-15 &lt; 2e-16
##
## P value adjustment method: none</code></pre>
<p>Post hoc analysis was performed conducting pairwise comparisons to determine which card type(s) differed in overall rating, pace, physicality, weak foot, and skill moves. All three card types were found to be significantly different from each other in terms of <strong>all</strong> player statistics after adjusting for multiple comparisons (Bonferroni alpha = .05/21 = 0.0024).</p>
<pre class="r"><code># ran 1 MANOVA, 5 ANOVA, and 15 (!) t-tests. Thus, performed 21 total tests
0.05/21 # Bonferroni adjusted alpha = 0.0024</code></pre>
<pre><code>## [1] 0.002380952</code></pre>
<pre class="r"><code>1 - ((1 - 0.05)^21)</code></pre>
<pre><code>## [1] 0.6594384</code></pre>
<pre class="r"><code># probability of at least one type I error being made is 0.6594. </code></pre>
<p>Throughout the process of determining if 5 key player ratings differ across card types (Rare, Non-Rare, and Icon) a total of 21 tests were performed (1 MANOVA, 5 ANOVA, and 15 t-tests). Using a significance level of 0.05, which is standard, we’d expect to have a 65.94% chance of making a Type I error - or observing a significant result when it is actually insignificant. Thus, the level of significance was adjusted using a Bonferroni correction (0.05/21 tests); now, any comparisons must have a p-value below 0.0024 in order to be designated significantly different from each other.</p>
<p>Even after adjusting the significance level, the three card types were significantly different from each of the others in all five numeric player rating categories. More in depth conclusions are given above.</p>
<p>Of the long list of MANOVA assumptions, it is unlikely that this data meets any of them. In particular, this data is almost certainly violating the multivariate normality assumption placed on dependent variables. Since player ratings are assigned by EA Sports (based on a player’s real-world performances), there is not a normal distribution across ratings. In fact, there are <em>many</em> more below-average players in FIFA 21 than high-rated players, so heavy skewing is expected. Furthermore, because these player ratings are assigned, this data does not represent a random sample of observations. Nonetheless, the assumption regarding a linear relationship among dependent variables is probably <strong>met</strong> since the higher a player’s rating is, the more common it would be to find high ratings in pace, physicality, and the other DVs used in the model.</p>
</div>
<div id="randomization-testing" class="section level2">
<h2>Randomization Testing</h2>
<p>Pace and Attacking Work Rate are really important in FIFA Ultimate Team. Players who have “High” Attacking Work Rates are more likely to push forward towards the goal they are attacking on when in possession of the ball. High work rates are desired because the user can count on that player being on the half of the field where the ball is, whether in possession or defense. Compared to others, players with High work rates will hustle to the ball more often, and just in general are found to be in better positions during the game.</p>
<p>Similarly, pace is really sought after in FUT. I’m not sure why, but even a small difference in pace between two players can drastically change how they “feel” in game. Plus, if a user is playing someone who’s entire team is faster than their own, it becomes increasingly challenging to “keep up” with the other player during the game. Finally, because most users prefer players with at least a Medium attacking work rate, I will only use players with High or Medium work rates. Therefore, a randomization experiment was conducted to see whether there was a difference in mean player pace between players with High and Medium Attacking Work Rates.</p>
<div id="null-hypothesis" class="section level3">
<h3>Null Hypothesis</h3>
<p><em>Mean player pace is the same for High and Medium Attacking Work Rate players.</em>
### Alternative Hypothesis
<em>Mean player pace is different for High and Medium Attacking Work Rate players.</em></p>
<pre class="r"><code>player_dat &lt;- tidier_nameless_players %&gt;% 
  filter(att_workrate == c(&quot;High&quot;, &quot;Med&quot;)) %&gt;% 
  select(pace, att_workrate) # dataset with only pace and High/Med work rates. 1,608 observations remain

rand_dist &lt;- vector() # empty vector to hold mean differences from permutation

for(i in 1:5000){ # loop resampling from data; calculating mean diff in pace after resampling
  new&lt;- data.frame(pace=sample(player_dat$pace), att_workrate=player_dat$att_workrate)
  rand_dist[i] &lt;- mean(new[new$att_workrate==&quot;High&quot;,]$pace) - mean(new[new$att_workrate==&quot;Med&quot;,]$pace)
}

player_dat %&gt;% group_by(att_workrate) %&gt;% summarize(means=mean(pace)) %&gt;% summarize(true_mean_diff = diff(means))#true mean diff = -8.1427</code></pre>
<pre><code>## # A tibble: 1 x 1
##   true_mean_diff
##            &lt;dbl&gt;
## 1          -8.14</code></pre>
<pre class="r"><code>{hist(rand_dist, 
      main=&quot;Null Distribution of Mean Diff. in Pace between High and Med. Attacking Work Rates&quot;,
      ylab=&quot;Frequency&quot;, 
      xlab=&quot;Randomized Distribution of Mean Differences&quot;, 
      breaks = 15, 
      xlim = c(-8.5,8.5), 
      col = &quot;purple&quot;); 
  abline(v = c(-8.1427, 8.1427), col=&quot;red&quot;)} </code></pre>
<p><img src="/project/project2_files/figure-html/Randomization%20Test%20for%20Difference%20in%20Mean%20Pace-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># test stat lines don&#39;t appear on null distribution because they are THAT far from what the expected mean difference is under a null distribution (no association)

mean(rand_dist&gt;8.1427 | rand_dist &lt; -8.1427) # p-value ~ 0; REJECT HO</code></pre>
<pre><code>## [1] 0</code></pre>
<p>Above, a randomization test was performed to determine if there was a difference in average pace based on if a player had a High or Medium Attacking Work Rate. After simulating the null distribution and finding the true mean difference in pace (8.1427), there is enough evidence to conclude there is a significant difference in a player’s average pace based on their High or Medium attacking work rate.
The histogram above depicts the null distribution of the simulated sample - in other words, the expected mean difference in pace if there was no association between pace and work rate. The true mean difference of 8.1427 was so far from the null distribution’s given statistic that the axis had to be expanded just to display it. The probability of observing a difference in pace as large as we observed based on chance alone (no association of variables) was reported to be 0 (it is likely just an infinitely small number). Thus, we may reject our null hypothesis and conclude that pace differs based on attacking work rate designation.</p>
</div>
</div>
<div id="linear-regression-model-with-interaction" class="section level2">
<h2>Linear Regression Model with Interaction</h2>
<pre class="r"><code># mean centering numeric predictors 
meanc_players &lt;- tidier_nameless_players %&gt;% 
  select(ps4_last, pace, overall, physicality, revision) %&gt;%
  mutate(pace_c=tidier_nameless_players$pace-mean(pace),
         overall_c=tidier_nameless_players$overall-mean(overall),
         phys_c=tidier_nameless_players$physicality-mean(physicality))
# fitting linear regression model to explain variation in player price on transfer market
model_fit &lt;- lm(ps4_last~pace_c+phys_c+revision+revision:pace_c, data=meanc_players) # Icon is reference group
summary(model_fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = ps4_last ~ pace_c + phys_c + revision +
revision:pace_c,
## data = meanc_players)
##
## Residuals:
## Min 1Q Median 3Q Max
## -1430883 -2731 -911 1225 3562461
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -612976.7 45471.0 -13.481 &lt;2e-16 ***
## pace_c 109281.9 2690.1 40.624 &lt;2e-16 ***
## phys_c 246.3 224.8 1.096 0.273
## revisionNon-Rare 613942.0 45567.5 13.473 &lt;2e-16 ***
## revisionRare 616188.8 45579.5 13.519 &lt;2e-16 ***
## pace_c:revisionNon-Rare -109236.8 2702.7 -40.417 &lt;2e-16
***
## pace_c:revisionRare -108877.2 2702.9 -40.282 &lt;2e-16 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 119000 on 3316 degrees of
freedom
## Multiple R-squared: 0.6075, Adjusted R-squared: 0.6068
## F-statistic: 855.3 on 6 and 3316 DF, p-value: &lt; 2.2e-16</code></pre>
<p><span class="math inline">\(\widehat{PlayerPrice} = -612,976.7 + 109,282(Pace) + 246.3(Physicality) + 613,942(NonRare) + 616,189(Rare) - 109,237(Pace*NonRare) - 108,877(Pace*Rare)\)</span></p>
<div id="models-coefficient-interpretations-ignoring-significance" class="section level3">
<h3>Model’s Coefficient Interpretations (ignoring significance)</h3>
<ul>
<li><p><strong>Intercept:</strong> Predicted auction price for a player with an average Pace <em>and</em> Physicality, who is an Icon, is -612,976.7 coins.</p></li>
<li><p><strong>Physicality:</strong> Controlling for Pace and card type (Revision status), for every 1 unit increase in a player’s physicality, their transfer market price is predicted to increase by 246.3 coins, on average (<em>t</em>=1.1, <em>df</em>=3316, <em>p</em>=0.273).</p></li>
<li><p><strong>Pace:</strong> Controlling for Physicality, <em>Icons</em> show an increase of 109,282 coins for every one unit increase in a player’s pace on average (<em>t</em>=40.62, <em>df</em>=3316, <em>p</em>&lt;.0001).</p></li>
<li><p><strong>revNonRare:</strong> Controlling for Physicality, in players of average Pace, transfer market price is 613,942 coins higher for Non-Rare players compared to Icons (<em>t</em>=13.47, <em>df</em>=3316, <em>p</em>&lt;.0001).</p></li>
<li><p><strong>revRare:</strong> Controlling for Physicality, in players of average Pace, transfer market price is 616,189 coins higher for Non-Rare players compared to Icons (<em>t</em>=13.52, <em>df</em>=3316, <em>p</em>&lt;.0001).</p></li>
<li><p><strong>pace:nonRare:</strong> Controlling for Physicality, the slope for Pace on Market Price is 109,237 times <em>lower</em> for Non-Rare card types compared to Icon card types (<em>t</em>=-40.42, <em>df</em>=3316, <em>p</em>&lt;.0001)</p></li>
<li><p><strong>pace:Rare:</strong> Controlling for Physicality, the slope for Pace on Market Price is 108,877 times <em>lower</em> for Rare card types compared to Icon card types (<em>t</em>=-40.28, <em>df</em>=3316, <em>p</em>&lt;.0001)</p></li>
</ul>
<pre class="r"><code># the minimum Pace value across the 3,000+ observations is Pace = 30 units. Thus, the scale is off when comparing pace held at 0 or the mean (dotted vs solid horizontal line, respectively)
ggplot(meanc_players, aes(pace, ps4_last, color=revision)) +
  geom_smooth(method = &quot;lm&quot;, se=F, fullrange=T) +
  geom_point() +
  xlab(&quot;Player Pace&quot;) +
  ylab(&quot;Transfer Market Price (Coins)&quot;) +
  geom_vline(xintercept = 0, lty=2)+
  geom_vline(xintercept = mean(meanc_players$pace))</code></pre>
<p><img src="/project/project2_files/figure-html/regression%20plot%201-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary(model_fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = ps4_last ~ pace_c + phys_c + revision +
revision:pace_c,
## data = meanc_players)
##
## Residuals:
## Min 1Q Median 3Q Max
## -1430883 -2731 -911 1225 3562461
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -612976.7 45471.0 -13.481 &lt;2e-16 ***
## pace_c 109281.9 2690.1 40.624 &lt;2e-16 ***
## phys_c 246.3 224.8 1.096 0.273
## revisionNon-Rare 613942.0 45567.5 13.473 &lt;2e-16 ***
## revisionRare 616188.8 45579.5 13.519 &lt;2e-16 ***
## pace_c:revisionNon-Rare -109236.8 2702.7 -40.417 &lt;2e-16
***
## pace_c:revisionRare -108877.2 2702.9 -40.282 &lt;2e-16 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 119000 on 3316 degrees of
freedom
## Multiple R-squared: 0.6075, Adjusted R-squared: 0.6068
## F-statistic: 855.3 on 6 and 3316 DF, p-value: &lt; 2.2e-16</code></pre>
<p>The graph above displays the predicted line of best fit for player’s transfer market price based on card type and player pace. As you can see, the LARGE majority of Rare and NonRare card types have auction prices near 0 (200-1500 coins), which pulls their groups line of best down to the point they <em>both</em> appear horizontal. A better relationship between card type (Icons) and pace on price is observed when looking just at the icon class. For them, there’s a pretty linear relationship between Pace and Price of the player on the market.</p>
<p>A player’s physicality, pace, card type, and the interaction between card type and pace explain 60.68% of the variation observed in Transfer Market Price (PS4) (Adj. R-sq = 0.6068, <em>df</em>=3316).</p>
</div>
<div id="assumptions-of-linearity-normality-and-homoskedasticity" class="section level3">
<h3>Assumptions of Linearity, Normality, and Homoskedasticity</h3>
<pre class="r"><code>resid &lt;- model_fit$residuals
fitvals &lt;- model_fit$fitted.values
# checking for equal variance across model
ggplot()+ geom_point(aes(fitvals, resid)) + 
  geom_hline(yintercept = 0, color=&quot;red&quot;) + ylab(&quot;Residuals&quot;) + 
  xlab(&quot;Fitted Values&quot;) # looks awful, definitely unequal variance and thus failed Homoskedasticity </code></pre>
<p><img src="/project/project2_files/figure-html/Assumptions%20from%20model_fit-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_histogram(aes(resid), bins=10) # DEFINITELY fails normality assumptions of residuals - everything is in the same bin </code></pre>
<p><img src="/project/project2_files/figure-html/Assumptions%20from%20model_fit-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>library(sandwich); library(lmtest)
bptest(model_fit) # reject Null (which was that data is Homoskedastic) so we KNOW data is Heteroskedastic</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  model_fit
## BP = 1149.7, df = 6, p-value &lt; 2.2e-16</code></pre>
<p>It is painfully evident from both graphs above that the data emphatically does NOT pass any of the assumptions for a linear regression model (linearity, equal variance, normality of residuals). The residuals were so close to each other in absolute value that they took up only one bin in the histogram, giving us more of a bar graph than anything else. Furthermore, a Breusch-Pagan test formally confirms the model is Heteroskedastic after observing a p-value &lt; .00001. Thus, running this model using robust standard errors, to account for the violated assumptions, will be a good next step.</p>
</div>
<div id="running-regression-model-with-robust-standard-errors-due-to-failed-homoskedastic-assumption" class="section level3">
<h3>Running Regression Model with Robust Standard Errors due to Failed Homoskedastic Assumption</h3>
<pre class="r"><code># model with corrected SEs
coeftest(model_fit, vcov = vcovHC(model_fit))[,1:2]</code></pre>
<pre><code>##                             Estimate  Std. Error
## (Intercept)             -612976.7107 455486.3695
## pace_c                   109281.9473  36811.8382
## phys_c                      246.2505    142.7756
## revisionNon-Rare         613942.0488 455530.7048
## revisionRare             616188.8227 455418.5193
## pace_c:revisionNon-Rare -109236.8339  36806.1852
## pace_c:revisionRare     -108877.2441  36804.5762</code></pre>
<pre class="r"><code># t- values from model:Pace_c (t=2.97); phys_c (t=1.72); nonRare (t=1.35); Rare (t=1.35); pace:nonRare(t=-2.97); pace:Rare(t=-2.96)</code></pre>
<p>After comparing the model’s regression results from before with the results using Robust Standard Errors, it’s evident that the violation of assumptions was falsely conflating the model’s prediction results. After running the regression with a more conservative test, the resulting t-value’s for <em>each</em> predictor was lower than |3|! Considering the initial model had values anywhere between 13 and 40 for t, the use of robust standard errors drastically changes the interpretation of results. While the interaction between pace and card type, and the main effect of Pace remain significant predictors of player transfer market price, a player’s physicality and the main effects of card type alone are no longer significant predictors!</p>
</div>
</div>
<div id="regression-model-using-bootstrapping-on-residuals-interaction-included" class="section level2">
<h2>Regression Model using Bootstrapping on Residuals, Interaction Included</h2>
<pre class="r"><code>model_fit &lt;- lm(ps4_last~pace_c+phys_c+revision+revision:pace_c, data=meanc_players) # Icon is reference group; fitting model
resids &lt;- model_fit$residuals # saves residuals from model (which were awful)
fitted &lt;- model_fit$fitted.values # saves yhats (i.e. predicted price) from model

resid_resamp&lt;- replicate(5000, {
  new_resids&lt;-sample(resids, replace=TRUE) #resamp residuals w replacement, saves as new_resids
  meanc_players$new_price &lt;- fitted+new_resids #adds new residuals to yhats to get new data
  fit&lt;-lm(new_price~pace_c+phys_c+revision+pace_c:revision, data=meanc_players) # refitting model
  coef(fit) # saves coefficient estimates
})
# estimated Standard Errors (SEs) from the Bootstrapped residual model
resid_resamp %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>## (Intercept) pace_c phys_c revisionNon-Rare revisionRare
pace_c:revisionNon-Rare
## 1 45368.15 2656.228 219.7549 45431.5 45515.98 2665.575
## pace_c:revisionRare
## 1 2670.12</code></pre>
<p>Above we have refit a linear regression model to the data after using bootstrapping resampling methods on the original model’s residuals. The estimated standard errors given from the bootstrapped model are shown above. Comparing these to the model using Robust Standard Errors, we notice that the SE values in the bootstrapped model are lower for main effects of pace, and the interaction of pace &amp; card type; however, the SEs in the bootstrapped model are <em>greater</em> for main effects of physicality and both levels of card type. Nonetheless, compared to the <em>original</em> regression model, the bootstrapped model is a better estimator of the data since we had initially violated so many assumptions. Finally, no changes in significance of main effects or interaction are observed when comparing this model to the one using robust standard errors. Considering the state and number of failed assumptions which arose, either of the latter two models are preferable when trying to interpret the effect of a player’s pace, card type, and physicality on their price.</p>
</div>
<div id="logistic-regression-model-predicting-dominant-foot-status-binary-from-some-predictors-no-interaction" class="section level2">
<h2>Logistic Regression Model Predicting Dominant Foot Status (Binary) from Some Predictors (no interaction)</h2>
<pre class="r"><code># coercing Right footedness (pref_foot) to be a 1; lefties will be a 0
binary_foot &lt;- tidier_nameless_players %&gt;% select(overall, passing, pref_foot, dribbling) %&gt;% mutate(y=ifelse(pref_foot==&quot;Right&quot;,1,0))
glimpse(binary_foot)</code></pre>
<pre><code>## Rows: 3,323
## Columns: 5
## $ overall &lt;dbl&gt; 85, 88, 86, 86, 89, 90, 95, 95, 87, 87,
88, 86, 90, 89, 91, 89, 89, 85, 88, 87,…
## $ passing &lt;dbl&gt; 56, 73, 77, 68, 82, 77, 90, 90, 85, 71,
79, 86, 83, 88, 75, 89, 62, 86, 87, 84,…
## $ pref_foot &lt;chr&gt; &quot;Right&quot;, &quot;Right&quot;, &quot;Right&quot;, &quot;Right&quot;,
&quot;Right&quot;, &quot;Right&quot;, &quot;Right&quot;, &quot;Left&quot;, &quot;Right&quot;,…
## $ dribbling &lt;dbl&gt; 56, 65, 81, 58, 90, 91, 95, 95, 87,
86, 82, 82, 93, 90, 87, 90, 67, 82, 88, 91,…
## $ y &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0…</code></pre>
<pre class="r"><code>log_fit&lt;-glm(y~overall+passing+dribbling, data=binary_foot, family=&quot;binomial&quot;) # fitting logistic model
coef(log_fit) %&gt;% round(5) %&gt;% data.frame # coefficients for eqtn in log-odds scales (additive)</code></pre>
<pre><code>##                    .
## (Intercept)  1.28624
## overall      0.02346
## passing     -0.03373
## dribbling    0.00421</code></pre>
<pre class="r"><code>coef(log_fit) %&gt;% exp %&gt;% round(5) %&gt;% data.frame #coefficients for eqtn in odds scale (multiplicative) - what ill use to interpret!</code></pre>
<pre><code>##                   .
## (Intercept) 3.61917
## overall     1.02374
## passing     0.96683
## dribbling   1.00422</code></pre>
<p><span class="math inline">\(\widehat{odds} = 3.62 * 1.02^R * 0.967^P * 1.00^D, where\: O=rating, \:P=passing,\: and\: D=dribbling\)</span></p>
<div id="interpretation-of-coefficients" class="section level3">
<h3>Interpretation of Coefficients</h3>
<ul>
<li>Controlling for player passing and dribbling stats, going up 1 unit in Overall Rating increases odds of being right footed by about 2%.</li>
<li>Controlling for player overall rating and dribbling stats, a 1 unit increase in passing statistics decreases the odds of being right footed by 3.3%.</li>
<li>Controlling for overall rating and passing stats, a 1 unit increase in dribbling statistics increases the odds of being right footed by 0.4%.</li>
</ul>
<pre class="r"><code>probs&lt;- predict(log_fit, type=&quot;response&quot;)
table(prediction=as.numeric(probs&gt;0.5), the_facts=binary_foot$y) %&gt;% addmargins</code></pre>
<pre><code>##           the_facts
## prediction    0    1  Sum
##        1    803 2520 3323
##        Sum  803 2520 3323</code></pre>
<pre class="r"><code>class_diag&lt;-function(probs,truth){
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

class_diag(probs = probs, truth = binary_foot$y)</code></pre>
<pre><code>##         acc sens spec       ppv       auc
## 1 0.7583509    1    0 0.7583509 0.5598094</code></pre>
<p>The confusion matrix obtained from the logistic regression model reveals the model did not classify a single player in the dataset as a Lefty!! Of the 3,323 observations, only 2,520 of the players are in-fact right-footed. However, the model incorrectly labeled the remaining 803 players who are <em>actually</em> left footed as right footed. From this alone, we expect our classification diagnositcs to be quite poor/low.</p>
<p>As expected, our classification diagnostics are pretty awful. First, the Area Under the Curve, a measurement that plots TPR vs FPR to explain the strength of the model’s predictions, is a measly 0.560. Ideally, AUC would be closer to 1; an AUC this low is associated with a BAD grade for the model’s predictions.</p>
<p>The accuracy of the model appears to not be so bad, but considering there are 0 True Negative Individuals, this value is being inflated with the True Positive count (since it classified <em>everyone</em> as right footed, bound to get all those correct). Sensitivity is the True positive count by the conditional positive, and it’s “great” rating is exclusively because the model correctly identified all right footed players as right footed; consequently, specificity is 0 because the model classified ALL players as right footed, so there is no true negative rate since it did not even account for any “negative” (lefty) values.</p>
<pre class="r"><code>binary_foot$logit&lt;-predict(log_fit,type=&quot;link&quot;) #get log-odds for everyone

binary_foot&lt;- binary_foot %&gt;% mutate(y=as.factor(y)) 

binary_foot %&gt;% ggplot() + 
  geom_density(aes(logit, color=y, fill=y), alpha=.4)+
  theme(legend.position = c(.85,.85))+
  geom_vline(xintercept=0)+xlab(&quot;logit (log-odds)&quot;)+
  geom_rug(aes(logit,color=y))+ 
  labs(caption=&quot;Logistic Regression Model performed very poorly in predicting a player&#39;s preffered foot (R or L). In fact, the 100% overlap  visually confirms that there were no players that the model predicted to be Left footed - even though there were over 800 of them.&quot;)</code></pre>
<p><img src="/project/project2_files/figure-html/Density%20Plot-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="roc-curve-plot" class="section level3">
<h3>ROC Curve Plot</h3>
<pre class="r"><code>library(plotROC) 
probs &lt;- predict(log_fit, type=&quot;response&quot;)
ROCplot &lt;- ggplot(binary_foot) + geom_roc(aes(d=pref_foot, m=probs), n.cuts=0)+ 
  geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2)

ROCplot</code></pre>
<p><img src="/project/project2_files/figure-html/ROC%20for%20log_model-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.5598188</code></pre>
<p>The ROC curve above reveals that our model is <em>not</em> predicting a player’s preferred foot well from just overall rating, passing, and dribbling statistics. An AUC of 0.56 confirms that our logistic regression model is not optimized to classify players into preferred foot categories. An ideal ROC plot would look like a Right (90 deg) angle, maximizing the TPR first and then the FPR.</p>
</div>
</div>
<div id="logistic-regression-model-predicting-preferred-foot-status-from-all-possible-or-useful-predictor-variables" class="section level2">
<h2>Logistic Regression Model Predicting Preferred Foot Status from ALL Possible (or Useful) Predictor Variables</h2>
<pre class="r"><code>binary_foot2 &lt;- tidier_nameless_players %&gt;% select(revision, overall, position, height, weight, intl_rep, pace, dribbling, shooting, passing, defending, physicality, att_workrate, def_workrate, weak_foot, skill_moves, ps4_prp, pref_foot) %&gt;%
  mutate(y=ifelse(pref_foot==&quot;Right&quot;,1,0))

binary_foot2&lt;- binary_foot2 %&gt;% select(-pref_foot) # removing truth column of foot (would be a perfect predictor)
glimpse(binary_foot2)</code></pre>
<pre><code>## Rows: 3,323
## Columns: 18
## $ revision &lt;chr&gt; &quot;Icon&quot;, &quot;Icon&quot;, &quot;Icon&quot;, &quot;Icon&quot;, &quot;Icon&quot;,
&quot;Icon&quot;, &quot;Icon&quot;, &quot;Icon&quot;, &quot;Icon&quot;, &quot;Ico…
## $ overall &lt;dbl&gt; 85, 88, 86, 86, 89, 90, 95, 95, 87, 87,
88, 86, 90, 89, 91, 89, 89, 85, 88, …
## $ position &lt;chr&gt; &quot;CB&quot;, &quot;LB&quot;, &quot;ST&quot;, &quot;RB&quot;, &quot;CF&quot;, &quot;ST&quot;,
&quot;CF&quot;, &quot;CAM&quot;, &quot;CF&quot;, &quot;ST&quot;, &quot;ST&quot;, &quot;CM&quot;, &quot;RW…
## $ height &lt;dbl&gt; 188, 186, 188, 178, 175, 183, 173, 165,
183, 184, 188, 191, 175, 180, 188, 1…
## $ weight &lt;dbl&gt; 89, 77, 78, 80, 76, 75, 69, 72, 78, 79,
81, 91, 68, 79, 80, 78, 75, 76, 76, …
## $ intl_rep &lt;dbl&gt; 3, 4, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 4,
5, 4, 4, 5, 4, 4, 3, 4, 4, 4, 4, 5, 4…
## $ pace &lt;dbl&gt; 84, 87, 87, 76, 95, 94, 96, 88, 76, 86, 86,
80, 90, 80, 79, 82, 76, 72, 88, …
## $ dribbling &lt;dbl&gt; 56, 65, 81, 58, 90, 91, 95, 95, 87,
86, 82, 82, 93, 90, 87, 90, 67, 82, 88, …
## $ shooting &lt;dbl&gt; 43, 54, 83, 45, 91, 90, 93, 91, 85, 88,
84, 80, 90, 85, 92, 77, 44, 80, 84, …
## $ passing &lt;dbl&gt; 56, 73, 77, 68, 82, 77, 90, 90, 85, 71,
79, 86, 83, 88, 75, 89, 62, 86, 87, …
## $ defending &lt;dbl&gt; 85, 90, 37, 88, 43, 42, 56, 42, 39,
40, 39, 83, 57, 38, 40, 36, 92, 44, 42, …
## $ physicality &lt;dbl&gt; 85, 78, 76, 89, 78, 72, 75, 75, 73,
72, 81, 78, 70, 77, 70, 62, 82, 66, 77, …
## $ att_workrate &lt;chr&gt; &quot;Med&quot;, &quot;Med&quot;, &quot;High&quot;, &quot;Med&quot;,
&quot;High&quot;, &quot;Med&quot;, &quot;High&quot;, &quot;High&quot;, &quot;Med&quot;, &quot;Med&quot;, &quot;H…
## $ def_workrate &lt;chr&gt; &quot;Med&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;High&quot;,
&quot;Med&quot;, &quot;Med&quot;, &quot;Med&quot;, &quot;Med&quot;, &quot;Low&quot;, &quot;Low&quot;, &quot;Low…
## $ weak_foot &lt;dbl&gt; 3, 4, 4, 3, 5, 4, 4, 3, 4, 4, 4, 5, 4,
4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3…
## $ skill_moves &lt;dbl&gt; 2, 2, 4, 2, 4, 4, 5, 5, 4, 4, 4, 3,
4, 5, 3, 4, 2, 4, 4, 5, 3, 3, 3, 3, 2, 3…
## $ ps4_prp &lt;dbl&gt; 48, 47, 60, 58, 52, 53, 67, 61, 59, 55,
62, 57, 70, 54, 53, 46, 49, 52, 63, …
## $ y &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1…</code></pre>
<pre class="r"><code>loggfit &lt;- glm(y~., data=binary_foot2, family = &quot;binomial&quot;) # fitting model with ALL predictors

prob_big &lt;- predict(loggfit, type=&quot;response&quot;) # pulling predicted probabilities
class_diag(probs = prob_big, truth = binary_foot2$y) #classification diagnostics</code></pre>
<pre><code>##         acc      sens      spec       ppv       auc
## 1 0.8164309 0.9765873 0.3138232 0.8170651 0.7836931</code></pre>
<pre class="r"><code>table(prediction=as.numeric(prob_big&gt;0.5), the_facts=binary_foot2$y) %&gt;% addmargins#confusion matrix; now model is at least predicting for each combination!</code></pre>
<pre><code>##           the_facts
## prediction    0    1  Sum
##        0    252   59  311
##        1    551 2461 3012
##        Sum  803 2520 3323</code></pre>
<p>After fitting our logistic regression model using 18 (!) predictor variables and still trying to predict a player’s preferred/strong foot, our classification diagnostics are MUCH higher. First off, Model Sensitivity is approaching 1, indicating that almost all right-footed players are being classified correctly. The AUC is also 0.78 for this model, representing a really drastic increase from 0.56 in the previous model. AUC would ideally be near 0.99, but it’s getting better. Accuracy, Positive Predictive Value (PPV) and specificity are all higher in this model as well. Considering we had 0 players classified as left-footed from the previous model, corresponding to a specificity score of 0, even some players being classified as left-footed (regardless of right or wrong) is making this model a better predictor.</p>
<pre class="r"><code>set.seed(1234)
k=10 #choose number of folds

data&lt;-binary_foot2[sample(nrow(binary_foot2)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(binary_foot2)),breaks=k,labels=F) #create folds

diags&lt;-NULL
for(i in 1:k){
  ## Create training and test sets
  train&lt;-data[folds!=i,]
  test&lt;-data[folds==i,]
  truth&lt;-test$y ## Truth labels for fold i
  
  ## Train model on training set (all but fold i)
  fit&lt;-glm(y~.,data=train,family=&quot;binomial&quot;)
  
  ## Test model on test set (fold i)
  probs&lt;-predict(fit,newdata = test,type=&quot;response&quot;)
  
  ## Get diagnostics for fold i
  diags&lt;-rbind(diags,class_diag(probs=probs,truth=truth))
}

summarize_all(diags, mean) # classification diagnostics averaged across all 10 (k) folds</code></pre>
<pre><code>##         acc      sens      spec       ppv       auc
## 1 0.8134131 0.9738735 0.3105989 0.8158426 0.7680507</code></pre>
<p>After performing ten-fold cross validation with the same logistic regression model as before, including 18 predictors looking to model the preferred foot of a player, we see that our classification diagnostics have actually gotten <em>worse</em> than before. AUC has dropped from 0.78 to 0.77, while Accuracy, sensitivity, and specificity experienced similarly small decreases in value when averaging across all 10 folds. Thus we can conclude that although this model is not the best, it is at least consistent in-sample and out of sample.</p>
<pre class="r"><code>library(glmnet)
y&lt;- as.matrix(binary_foot2$y) #grab response variable, preferred foot
x&lt;- model.matrix(y~-1+., data=binary_foot2) #grab predictors

x&lt;-scale(x) #standardizing predictors

cv&lt;-cv.glmnet(x,y,family=&quot;binomial&quot;) #picks an optimal value for lambda through 10-fold CV
#we can plot cv, grab glmnet.fit, lamba, label it 
{plot(cv$glmnet.fit, &quot;lambda&quot;, label=TRUE); abline(v = log(cv$lambda.1se)); abline(v = log(cv$lambda.min),lty=2)}</code></pre>
<p><img src="/project/project2_files/figure-html/LASSO%20Regularization-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>cv&lt;-cv.glmnet(x,y,family=&quot;binomial&quot;) #picks an optimal value for lambda through 10-fold CV
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se) # runs the same, but just want output where lamba is equal to the lamba-min+1SE
coef(lasso)</code></pre>
<pre><code>## 34 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                           s0
## (Intercept)       1.30366991
## revisionIcon      .         
## revisionNon-Rare  .         
## revisionRare      .         
## overall           .         
## positionCB       -0.03062998
## positionCDM       0.05594897
## positionCF        .         
## positionCM        0.04644401
## positionLB       -0.75866864
## positionLM       -0.15038593
## positionLW        .         
## positionLWB      -0.16107406
## positionRB        0.53439398
## positionRM        .         
## positionRW       -0.09765682
## positionRWB       .         
## positionST        .         
## height            .         
## weight            .         
## intl_rep          0.09365435
## pace              .         
## dribbling         .         
## shooting          .         
## passing          -0.29292165
## defending         .         
## physicality       0.03195158
## att_workrateLow   .         
## att_workrateMed   .         
## def_workrateLow   .         
## def_workrateMed   .         
## weak_foot         0.27217480
## skill_moves       .         
## ps4_prp           .</code></pre>
<pre class="r"><code># if we want a model that makes good predictions while minimizing the penalty, lasso suggests we only use position(s)[CB, CDM, CM, LB, LM, LWB, RB, &amp; RW] as well as intl_rep, passing, physicality, and weak foot. ALL other predictors get dropped to 0!</code></pre>
<pre class="r"><code>set.seed(1234)
k=10 #number of folds

#need to create dummy variables for the multitude of player positions
binary_foot2&lt;- binary_foot2 %&gt;% mutate(CB = ifelse(binary_foot2$position==&quot;CB&quot;,1,0),
                                       CDM = ifelse(binary_foot2$position==&quot;CDM&quot;,1,0),
                                       CM = ifelse(binary_foot2$position==&quot;CM&quot;,1,0),
                                       LB = ifelse(binary_foot2$position==&quot;LB&quot;,1,0),
                                       LM = ifelse(binary_foot2$position==&quot;LM&quot;,1,0),
                                       LWB = ifelse(binary_foot2$position==&quot;LWB&quot;,1,0),
                                       RB = ifelse(binary_foot2$position==&quot;RB&quot;,1,0),
                                       RW = ifelse(binary_foot2$position==&quot;RW&quot;,1,0),
                                       RWB = ifelse(binary_foot2$position==&quot;RWB&quot;,1,0))

data1&lt;-binary_foot2[sample(nrow(binary_foot2)),] #randomly orders rows
folds&lt;- cut(seq(1:nrow(binary_foot2)), breaks=k, labels=F) #folds

diags&lt;- NULL
for(i in 1:k){
  ## create training and test sets
  train&lt;-data1[folds!=i,]
  test&lt;-data1[folds==i,]
  truth&lt;-test$y
  
  fit&lt;-glm(y~CB+CDM+CM+LB+LM+LWB+RB+RW+RWB+height+intl_rep+passing+physicality+weak_foot, data=train, family=&quot;binomial&quot;)
  probs&lt;- predict(fit, newdata=test, type=&quot;response&quot;)
  
  diags&lt;-rbind(diags, class_diag(probs, truth))
}
diags %&gt;% summarize_all(mean)</code></pre>
<pre><code>##         acc      sens      spec       ppv      auc
## 1 0.8152212 0.9766164 0.3090308 0.8159638 0.775593</code></pre>
<p>After performing Lasso Regularization and identifying which predictor variables are the most important in predicting a player’s strong foot, a 10-fold cross validation of the logistic regression model was performed using the refined predictors. Like previously, our average out-of-sample AUC is hovering near 0.77; this AUC indicates the model’s prediction strength is “okay” at best, and there were no significant jumps in AUC after LASSO + CV. The same trends can be reported for the other classification diagnostics. It seems that sensitivity remains high throughout the model’s because the model is most often predicting a player is right-footed, and most of the time it is correct (since most <em>are</em> right footed). In conclusion, the logistic regression model predicting a player’s strong foot is okay, but not great - across all 4 “permutations” we did of it. Stepping back and thinking about soccer as a whole, there are a few positions where footed-ness is important, but most of them don’t matter. For example, most Right-Backs (hugs the right sideline, defender) are right-footed players and vice-versa for Left backs and Left-footedness. This is observed because of the natural tendency of Fullbacks to be crossing the ball into the box (where their team is attacking) using their stronger foot. A left-footed Right Back would be crossing the ball most often with their Right-foot, which wouldn’t be preferred! Thus, it wasn’t surprising seeing that LASSO picked most of the Wide player positions (LM/RM, LB/RB, and LW/RW) to be included in the model! However, it is neat that we saw a real-world preference be observed and selected for by the LASSO regularization.</p>
</div>
</div>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/docs.min.js"></script>
<script src="/js/main.js"></script>

<script src="/js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
